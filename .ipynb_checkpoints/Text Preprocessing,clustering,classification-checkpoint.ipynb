{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mscit5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mscit5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== After preprocessing the document is===========\n",
      "any remake of an alfred hitchcock film is at best an uncertain project a perfect murder illustrates nfrankly dial for murder is not one of the master director greatest effort so there is ample room for improvement nunfortunately instead of updating the script ironing out some of the fault and speeding up the pace little perfect murder ha inexplicably managed to eliminate almost everything that wa worthwhile about dial for murder leaving behind the nearly unwatchable wreckage of would be 90 thriller nalmost all suspense film are loaded with plot implausibility nthe best thriller keep viewer involved enough in what going on so that these flaw in logic don become apparent until long after the final credit have rolled nunfortunately in perfect murder the fault are often so overt that we become aware of them a they re happening nthis is very bad sign nnot only do such occurrence shatter any suspension of disbelief but they have the astute viewer looking for the next such blunder nof course in the case of perfect murder at least that give an audience member something to do besides concentrating on the inane plot and the lifeless cardboard character na perfect murder isn a strict remake of dial for murder but it doe borrow heavily from frederick knott play which wa also the source material for hitchcock version a well a 1981 made for tv retelling nemily hayes gwyneth paltrow is the wealthy wife of powerful wall street mover and shaker steven hayes michael douglas ntheir marriage isn going well emily resents steven controlling instinct and a form of rebellion she is having an affair with penniless painter david shaw viggo mortensen nwhen steven learns of the relationship he decides to confront david but his approach isn that of typical cuckolded husband ninstead of yelling or threatening steven offer david proposal that too good to resist for 500 000 in cash 100 000 before the rest after he is to break into steven new york apartment and kill emily of course after getting the first payment david never bother to ask how he supposed to get the rest nultimately m not sure which of the three main character we re supposed to be sympathetic to the cold hearted husband who want his wife dead so he can get his hand on her fortune her mercenary lover who is willing to do the deed for half million or the woman who is happily carrying on an extramarital affair nnot only are these individual all profoundly dislikable but they re not interesting it possible to make good movie with detestable character see reservoir dog but there ha to be something compelling about them which in this case there isn nsteven emily and david are all lifted directly from the screenwriting 101 text book on stereotype nthe actor in this film are obviously just on hand to get their paycheck nmichael douglas is playing the kind of heartless tycoon that he can do in his sleep he gordon gekko with an unfaithful wife ngwyneth paltrow who wa recently delightful and appealing in sliding door is simply awful here nshe now ha the dubious distinction of have starred in two of 1998 worst thriller the other being hush nat least viggo mortensen i njane ha little fun with his part but then he usually doe interesting thing even in bad movie nthe thin supporting cast includes david suchet the star of poirot a police inspector and sarita choudhury kama sutra a emily best friend na perfect murder is plodding production that generates almost no suspense from beginning to end nthere aren many twist and turn in the unexpectedly linear script which make the ending inevitable almost from the start nit surprising to see director andrew davis the man behind the fugitive involved in this mess but like his star he too need to earn living nit just that remaking hitchcock and doing it so badly hardly seems to be an honorable way to go about getting the dough\n",
      "[0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0\n",
      " 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1\n",
      " 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0\n",
      " 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1\n",
      " 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0\n",
      " 1 1 0 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0\n",
      " 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 0 1 0 1\n",
      " 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0]\n",
      "==================Confusion Matrix==================\n",
      "[[180  28]\n",
      " [ 30 162]]\n",
      "==================Classification Report==================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       208\n",
      "           1       0.85      0.84      0.85       192\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.85      0.85      0.85       400\n",
      "weighted avg       0.85      0.85      0.85       400\n",
      "\n",
      "==================Accuracy Score==================\n",
      "0.855\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import re   #Use to returns only the first match to the pattern from the target string\n",
    "import nltk   # NLP library\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')  # In NLP, use to eliminate unimportant words, only focus on important words\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "movie_data = load_files(r\"C:\\Users\\Mscit5\\Downloads\\ML practical\\txt_sentoken\")  # Folder Path \n",
    "print(\"============Before preprocessing the document is============\")\n",
    "print(movie_data)\n",
    "print()\n",
    "X, y = movie_data.data, movie_data.target # X=feature and y=target\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')   # wordnet use to find the meanings of words, synonyms, antonyms, and more\n",
    "# Text Preprocessing\n",
    "documents = []\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization used to generate root form of derived (inflected) words\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)\n",
    "print(\"=========== After preprocessing the document is===========\" ) \n",
    "print(document)\n",
    "# Converting Text to Numbers    \n",
    "# Bag of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()\n",
    "\n",
    "# Converting text to number using the bag of words model into TFIDF values\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()\n",
    "\n",
    "# Training and Testing Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Training Text Classification Model and Predicting Sentiment\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train) \n",
    "y_pred = classifier.predict(X_test)\n",
    "print()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"==================Confusion Matrix==================\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"==================Classification Report==================\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"==================Accuracy Score==================\")\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=60, n_init=100, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed=tfidfconverter.transform(X_train)\n",
    "\n",
    "# Clustering the training sentences with K-means technique\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "modelkmeans = KMeans(n_clusters=60, init='k-means++', n_init=100)\n",
    "modelkmeans.fit(X_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping umap as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'umap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-8a115d7974a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtfidf_vectriozer\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtfidf_word_doc_matrix\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtfidf_vectriozer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovie_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'umap'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import umap\n",
    "import umap.plot\n",
    "tfidf_vectriozer= TfidfVectorizer(min_df=5, stop_words='english')\n",
    "tfidf_word_doc_matrix= tfidf_vectriozer.fit_transform(movie_data.data)\n",
    "embedding= umap.UMAP(n_components=2, metric='cosine').fit(tfidf_word_doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = load_files(r\"C:\\Users\\Mscit5\\Downloads\\ML practical\\txt_sentoken\")  # Folder Path\n",
    "X, y = movie_data.data, movie_data.target # X=feature and y=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mscit5\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')   # wordnet use to find the meanings of words, synonyms, antonyms, and more\n",
    "print(\"==================Text Preprocessing==================\")\n",
    "documents = []\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization used to generate root form of derived (inflected) words\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)\n",
    "print(\"After preprocessing document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the bag of words model into TFIDF values\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Training Text Classification Model and Predicting Sentiment\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0\n",
      " 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1\n",
      " 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0\n",
      " 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1\n",
      " 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0\n",
      " 1 1 0 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0\n",
      " 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 0 1 0 1\n",
      " 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Confusion Matrix==================\n",
      "[[180  28]\n",
      " [ 30 162]]\n",
      "==================Classification Report==================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       208\n",
      "           1       0.85      0.84      0.85       192\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.85      0.85      0.85       400\n",
      "weighted avg       0.85      0.85      0.85       400\n",
      "\n",
      "==================Accuracy Score==================\n",
      "0.855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"==================Confusion Matrix==================\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"==================Classification Report==================\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"==================Accuracy Score==================\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'any remake of an alfred hitchcock film is at best an uncertain project a perfect murder illustrates nfrankly dial for murder is not one of the master director greatest effort so there is ample room for improvement nunfortunately instead of updating the script ironing out some of the fault and speeding up the pace little perfect murder ha inexplicably managed to eliminate almost everything that wa worthwhile about dial for murder leaving behind the nearly unwatchable wreckage of would be 90 thriller nalmost all suspense film are loaded with plot implausibility nthe best thriller keep viewer involved enough in what going on so that these flaw in logic don become apparent until long after the final credit have rolled nunfortunately in perfect murder the fault are often so overt that we become aware of them a they re happening nthis is very bad sign nnot only do such occurrence shatter any suspension of disbelief but they have the astute viewer looking for the next such blunder nof course in the case of perfect murder at least that give an audience member something to do besides concentrating on the inane plot and the lifeless cardboard character na perfect murder isn a strict remake of dial for murder but it doe borrow heavily from frederick knott play which wa also the source material for hitchcock version a well a 1981 made for tv retelling nemily hayes gwyneth paltrow is the wealthy wife of powerful wall street mover and shaker steven hayes michael douglas ntheir marriage isn going well emily resents steven controlling instinct and a form of rebellion she is having an affair with penniless painter david shaw viggo mortensen nwhen steven learns of the relationship he decides to confront david but his approach isn that of typical cuckolded husband ninstead of yelling or threatening steven offer david proposal that too good to resist for 500 000 in cash 100 000 before the rest after he is to break into steven new york apartment and kill emily of course after getting the first payment david never bother to ask how he supposed to get the rest nultimately m not sure which of the three main character we re supposed to be sympathetic to the cold hearted husband who want his wife dead so he can get his hand on her fortune her mercenary lover who is willing to do the deed for half million or the woman who is happily carrying on an extramarital affair nnot only are these individual all profoundly dislikable but they re not interesting it possible to make good movie with detestable character see reservoir dog but there ha to be something compelling about them which in this case there isn nsteven emily and david are all lifted directly from the screenwriting 101 text book on stereotype nthe actor in this film are obviously just on hand to get their paycheck nmichael douglas is playing the kind of heartless tycoon that he can do in his sleep he gordon gekko with an unfaithful wife ngwyneth paltrow who wa recently delightful and appealing in sliding door is simply awful here nshe now ha the dubious distinction of have starred in two of 1998 worst thriller the other being hush nat least viggo mortensen i njane ha little fun with his part but then he usually doe interesting thing even in bad movie nthe thin supporting cast includes david suchet the star of poirot a police inspector and sarita choudhury kama sutra a emily best friend na perfect murder is plodding production that generates almost no suspense from beginning to end nthere aren many twist and turn in the unexpectedly linear script which make the ending inevitable almost from the start nit surprising to see director andrew davis the man behind the fugitive involved in this mess but like his star he too need to earn living nit just that remaking hitchcock and doing it so badly hardly seems to be an honorable way to go about getting the dough'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
